{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text classification using Transfer learning[ BERT].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5el_8SqFqVAT"
      },
      "source": [
        "\n",
        "In this notebook, You will do amazon review classification with BERT.[Download data from [this](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) link]\n",
        "<pre> \n",
        "It contains 5 parts as below.  Detailed instrctions are given in the each cell. please read every comment we have written. \n",
        "    1. Preprocessing \n",
        "    2. Creating a BERT model from the Tensorflow HUB.\n",
        "    3. Tokenization\n",
        "    4. getting the pretrained embedding Vector for a given review from the BERT.\n",
        "    5. Using the embedding data apply NN and classify the reviews.\n",
        "    6. Creating a Data pipeline for BERT Model. \n",
        "\n",
        "<font size=5>instructions:</font>\n",
        "\n",
        "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. \n",
        "    If you manipulate any, it will be considered as plagiarised. \n",
        "    \n",
        "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
        "    \n",
        "    3. please return outputs in the same format what we asked. Eg. Don't return List if we are asking for a numpy array.\n",
        "    \n",
        "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
        "    \n",
        "    5. We are giving instructions at each section if necessary, please follow them. \n",
        "\n",
        "<font size=5>Every Grader function has to return True. </font>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOtG4cf0qVAZ"
      },
      "source": [
        "#all imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OcmiHdAJqVAi",
        "outputId": "d66d2ee2-aa11-4cd1-d834-d70cd0379382"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTWRqbrBqVAu"
      },
      "source": [
        "<pre><font size=6>Part-1: Preprocessing</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xokNn7qZqVAz"
      },
      "source": [
        "#get only 2 columns - Text, Score\n",
        "#drop the NAN values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZHYOFXlNFkN"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3csZKDrqVAv"
      },
      "source": [
        "#Read the dataset - Amazon fine food reviews\n",
        "reviews = pd.read_csv(r\"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/Copy of Reviews.csv\")\n",
        "#check the info of the dataset\n",
        "reviews.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxdMK-IONlEB"
      },
      "source": [
        "reviews= reviews[reviews.Score != 3]\n",
        "reviews.Score = reviews.Score.apply(lambda x:1 if x>3 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMPEWpa-UOMG"
      },
      "source": [
        "reviews = reviews[['Text','Score']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GZt7pVkqVA4",
        "outputId": "481301cc-30a6-4bc3-8793-a1e5bb59297b"
      },
      "source": [
        "#if score> 3, set score = 1\n",
        "#if score<=2, set score = 0\n",
        "#if score == 3, remove the rows. \n",
        "reviews.Score.value_counts()[1],reviews.shape\n",
        "reviews.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text     0\n",
              "Score    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYZ-UB9UqVA-"
      },
      "source": [
        "def get_wordlen(x):\n",
        "    return len(x.split())\n",
        "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
        "reviews = reviews[reviews.len<50]\n",
        "reviews = reviews.sample(n=100000, random_state=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "4vmt2CpGa3-k",
        "outputId": "98f93c54-8a37-49fe-d598-2ec0ffee42b6"
      },
      "source": [
        "reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64117</th>\n",
              "      <td>The tea was of great quality and it tasted lik...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418112</th>\n",
              "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357829</th>\n",
              "      <td>Great product. Does not completely get rid of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175872</th>\n",
              "      <td>This gum is my favorite!  I would advise every...</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178716</th>\n",
              "      <td>I also found out about this product because of...</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336657</th>\n",
              "      <td>Using this coffee and a stove top espresso mak...</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498034</th>\n",
              "      <td>THE TASTE OF THIS M&amp;M IS THE BEST. I USED IT I...</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357766</th>\n",
              "      <td>Excellent Tea. I enjoy a cup every now and the...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326811</th>\n",
              "      <td>These oatmeal cookies have a great spice taste...</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19261</th>\n",
              "      <td>This is the best coffee ever! I will never dri...</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Text  Score  len\n",
              "64117   The tea was of great quality and it tasted lik...      1   30\n",
              "418112  My cat loves this.  The pellets are nice and s...      1   31\n",
              "357829  Great product. Does not completely get rid of ...      1   41\n",
              "175872  This gum is my favorite!  I would advise every...      1   27\n",
              "178716  I also found out about this product because of...      1   22\n",
              "...                                                   ...    ...  ...\n",
              "336657  Using this coffee and a stove top espresso mak...      1   39\n",
              "498034  THE TASTE OF THIS M&M IS THE BEST. I USED IT I...      1   28\n",
              "357766  Excellent Tea. I enjoy a cup every now and the...      1   21\n",
              "326811  These oatmeal cookies have a great spice taste...      1   23\n",
              "19261   This is the best coffee ever! I will never dri...      1   28\n",
              "\n",
              "[100000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvldQriGqVBB"
      },
      "source": [
        "#remove HTML from the Text column and save in the Text column only\n",
        "import re\n",
        "reviews.Text=reviews.Text.apply(lambda x :re.sub(r'<.*?>', '',x))\n",
        "#reviews.Text=reviews.Text.apply(lambda x :i.strip() for i in x.split                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhfN1s2mqVBD"
      },
      "source": [
        "#print head 5\n",
        "reviews.head(5)\n",
        "X = reviews.loc[:,['Text']]\n",
        "y = reviews.Score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgCocLpfjzJs"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "y = pd.Series(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsYDd3okqVBF"
      },
      "source": [
        "#split the data into train and test data(20%) with Stratify sampling, random state 33,\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train , X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,shuffle= True,random_state=100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQKhv7OUm4W5",
        "outputId": "925b6847-9049-48be-9a2f-a85f2ca9b534"
      },
      "source": [
        "y_train.value_counts(),y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1    69613\n",
              " 0    10387\n",
              " Name: Score, dtype: int64, 1    17391\n",
              " 0     2609\n",
              " Name: Score, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i04NePAz-x-_",
        "outputId": "73aeadf2-f23a-4133-f941-bc37739a206c"
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "-Q6OAcrOqVBI",
        "outputId": "f5e06039-60d0-4eaf-8035-ea8e1b739e68"
      },
      "source": [
        "#plot bar graphs of y_train and y_test\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.countplot(y_train)\n",
        "plt.title('Train')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "UPmlWlBnwsQJ",
        "outputId": "c5919c6e-ef0f-4148-e218-7af32db9b9bf"
      },
      "source": [
        "sns.countplot(y_test)\n",
        "plt.title('Test')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-z5boWqVBK"
      },
      "source": [
        "#saving to disk. if we need, we can load preprocessed data directly. \n",
        "reviews.to_csv('/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/preprocessed.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fRwvGFZRm0p"
      },
      "source": [
        "# Part-2: Creating BERT Model \n",
        "For this assignment, we are using BERT uncased Base model. \n",
        "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8xd2HejqVBN"
      },
      "source": [
        "## Loading the Pretrained Model from tensorflow HUB\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
        "max_seq_length = 55\n",
        "\n",
        "#BERT takes 3 inputs\n",
        "\n",
        "#this is input words. Sequence of words represented as integers\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "#mask vector if you are padding anything\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
        "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
        "#second seq segment vector are 1's\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "#bert layer \n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "#Bert model\n",
        "#We are using only pooled output not sequence out. \n",
        "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
        "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQJsjg6fqVBQ",
        "outputId": "5e856f51-ea3a-42f2-cfc7-435a72563d15"
      },
      "source": [
        "bert_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 55, 768)]                 'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,482,241\n",
            "Trainable params: 0\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewv4hFCsqVBU"
      },
      "source": [
        "<pre><font size=6>Part-3: Tokenization</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX3VEFjiqVBU"
      },
      "source": [
        "#getting Vocab file\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_iPwa99qVBW",
        "outputId": "065fd09b-5d6e-4bf0-db78-1735ff607582"
      },
      "source": [
        "#import tokenization - We have given tokenization.py file\n",
        "vocab_file,do_lower_case"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(b'/tmp/tfhub_modules/03d6fb3ce1605ad9e5e9ed5346b2fb9623ef4d3d/assets/vocab.txt',\n",
              " True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSj8onNyKzeL",
        "outputId": "52b7b62b-0b0d-45ff-ffbc-70cebf1f2a6b"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Tokenization classes implementation.\n",
        "\n",
        "The file is forked from:\n",
        "https://github.com/google-research/bert/blob/master/tokenization.py.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import six\n",
        "import tensorflow as tf\n",
        "!pip install sentencepiece\n",
        "import sentencepiece as spm\n",
        "#! pip install s\n",
        "#import s\n",
        "SPIECE_UNDERLINE = \"â\"\n",
        "\n",
        "\n",
        "def validate_case_matches_checkpoint(do_lower_case, init_checkpoint):\n",
        "  \"\"\"Checks whether the casing config is consistent with the checkpoint name.\"\"\"\n",
        "\n",
        "  # The casing has to be passed in by the user and there is no explicit check\n",
        "  # as to whether it matches the checkpoint. The casing information probably\n",
        "  # should have been stored in the bert_config.json file, but it's not, so\n",
        "  # we have to heuristically detect it to validate.\n",
        "\n",
        "  if not init_checkpoint:\n",
        "    return\n",
        "\n",
        "  m = re.match(\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\", init_checkpoint)\n",
        "  if m is None:\n",
        "    return\n",
        "\n",
        "  model_name = m.group(1)\n",
        "\n",
        "  lower_models = [\n",
        "      \"uncased_L-24_H-1024_A-16\", \"uncased_L-12_H-768_A-12\",\n",
        "      \"multilingual_L-12_H-768_A-12\", \"chinese_L-12_H-768_A-12\"\n",
        "  ]\n",
        "\n",
        "  cased_models = [\n",
        "      \"cased_L-12_H-768_A-12\", \"cased_L-24_H-1024_A-16\",\n",
        "      \"multi_cased_L-12_H-768_A-12\"\n",
        "  ]\n",
        "\n",
        "  is_bad_config = False\n",
        "  if model_name in lower_models and not do_lower_case:\n",
        "    is_bad_config = True\n",
        "    actual_flag = \"False\"\n",
        "    case_name = \"lowercased\"\n",
        "    opposite_flag = \"True\"\n",
        "\n",
        "  if model_name in cased_models and do_lower_case:\n",
        "    is_bad_config = True\n",
        "    actual_flag = \"True\"\n",
        "    case_name = \"cased\"\n",
        "    opposite_flag = \"False\"\n",
        "\n",
        "  if is_bad_config:\n",
        "    raise ValueError(\n",
        "        \"You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. \"\n",
        "        \"However, `%s` seems to be a %s model, so you \"\n",
        "        \"should pass in `--do_lower_case=%s` so that the fine-tuning matches \"\n",
        "        \"how the model was pre-training. If this error is wrong, please \"\n",
        "        \"just comment out this check.\" %\n",
        "        (actual_flag, init_checkpoint, model_name, case_name, opposite_flag))\n",
        "\n",
        "\n",
        "def convert_to_unicode(text):\n",
        "  \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
        "  if six.PY3:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, bytes):\n",
        "      return text.decode(\"utf-8\", \"ignore\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  elif six.PY2:\n",
        "    if isinstance(text, str):\n",
        "      return text.decode(\"utf-8\", \"ignore\")\n",
        "    elif isinstance(text, unicode):\n",
        "      return text\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  else:\n",
        "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
        "\n",
        "\n",
        "def printable_text(text):\n",
        "  \"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"\n",
        "\n",
        "  # These functions want `str` for both Python2 and Python3, but in one case\n",
        "  # it's a Unicode string and in the other it's a byte string.\n",
        "  if six.PY3:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, bytes):\n",
        "      return text.decode(\"utf-8\", \"ignore\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  elif six.PY2:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, unicode):\n",
        "      return text.encode(\"utf-8\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  else:\n",
        "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
        "\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "  \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
        "  vocab = collections.OrderedDict()\n",
        "  index = 0\n",
        "  with tf.io.gfile.GFile(vocab_file, \"r\") as reader:\n",
        "    while True:\n",
        "      token = convert_to_unicode(reader.readline())\n",
        "      if not token:\n",
        "        break\n",
        "      token = token.strip()\n",
        "      vocab[token] = index\n",
        "      index += 1\n",
        "  return vocab\n",
        "\n",
        "\n",
        "def convert_by_vocab(vocab, items):\n",
        "  \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n",
        "  output = []\n",
        "  for item in items:\n",
        "    output.append(vocab[item])\n",
        "  return output\n",
        "\n",
        "\n",
        "def convert_tokens_to_ids(vocab, tokens):\n",
        "  return convert_by_vocab(vocab, tokens)\n",
        "\n",
        "\n",
        "def convert_ids_to_tokens(inv_vocab, ids):\n",
        "  return convert_by_vocab(inv_vocab, ids)\n",
        "\n",
        "\n",
        "def whitespace_tokenize(text):\n",
        "  \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
        "  text = text.strip()\n",
        "  if not text:\n",
        "    return []\n",
        "  tokens = text.split()\n",
        "  return tokens\n",
        "\n",
        "\n",
        "class FullTokenizer(object):\n",
        "  \"\"\"Runs end-to-end tokenziation.\"\"\"\n",
        "\n",
        "  def __init__(self, vocab_file, do_lower_case=True, split_on_punc=True):\n",
        "    self.vocab = load_vocab(vocab_file)\n",
        "    self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "    self.basic_tokenizer = BasicTokenizer(\n",
        "        do_lower_case=do_lower_case, split_on_punc=split_on_punc)\n",
        "    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    split_tokens = []\n",
        "    for token in self.basic_tokenizer.tokenize(text):\n",
        "      for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
        "        split_tokens.append(sub_token)\n",
        "\n",
        "    return split_tokens\n",
        "\n",
        "  def convert_tokens_to_ids(self, tokens):\n",
        "    return convert_by_vocab(self.vocab, tokens)\n",
        "\n",
        "  def convert_ids_to_tokens(self, ids):\n",
        "    return convert_by_vocab(self.inv_vocab, ids)\n",
        "\n",
        "\n",
        "class BasicTokenizer(object):\n",
        "  \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n",
        "\n",
        "  def __init__(self, do_lower_case=True, split_on_punc=True):\n",
        "    \"\"\"Constructs a BasicTokenizer.\n",
        "\n",
        "    Args:\n",
        "      do_lower_case: Whether to lower case the input.\n",
        "      split_on_punc: Whether to apply split on punctuations. By default BERT\n",
        "        starts a new token for punctuations. This makes detokenization difficult\n",
        "        for tasks like seq2seq decoding.\n",
        "    \"\"\"\n",
        "    self.do_lower_case = do_lower_case\n",
        "    self.split_on_punc = split_on_punc\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    \"\"\"Tokenizes a piece of text.\"\"\"\n",
        "    text = convert_to_unicode(text)\n",
        "    text = self._clean_text(text)\n",
        "\n",
        "    # This was added on November 1st, 2018 for the multilingual and Chinese\n",
        "    # models. This is also applied to the English models now, but it doesn't\n",
        "    # matter since the English models were not trained on any Chinese data\n",
        "    # and generally don't have any Chinese data in them (there are Chinese\n",
        "    # characters in the vocabulary because Wikipedia does have some Chinese\n",
        "    # words in the English Wikipedia.).\n",
        "    text = self._tokenize_chinese_chars(text)\n",
        "\n",
        "    orig_tokens = whitespace_tokenize(text)\n",
        "    split_tokens = []\n",
        "    for token in orig_tokens:\n",
        "      if self.do_lower_case:\n",
        "        token = token.lower()\n",
        "        token = self._run_strip_accents(token)\n",
        "      if self.split_on_punc:\n",
        "        split_tokens.extend(self._run_split_on_punc(token))\n",
        "      else:\n",
        "        split_tokens.append(token)\n",
        "\n",
        "    output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
        "    return output_tokens\n",
        "\n",
        "  def _run_strip_accents(self, text):\n",
        "    \"\"\"Strips accents from a piece of text.\"\"\"\n",
        "    text = unicodedata.normalize(\"NFD\", text)\n",
        "    output = []\n",
        "    for char in text:\n",
        "      cat = unicodedata.category(char)\n",
        "      if cat == \"Mn\":\n",
        "        continue\n",
        "      output.append(char)\n",
        "    return \"\".join(output)\n",
        "\n",
        "  def _run_split_on_punc(self, text):\n",
        "    \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
        "    chars = list(text)\n",
        "    i = 0\n",
        "    start_new_word = True\n",
        "    output = []\n",
        "    while i < len(chars):\n",
        "      char = chars[i]\n",
        "      if _is_punctuation(char):\n",
        "        output.append([char])\n",
        "        start_new_word = True\n",
        "      else:\n",
        "        if start_new_word:\n",
        "          output.append([])\n",
        "        start_new_word = False\n",
        "        output[-1].append(char)\n",
        "      i += 1\n",
        "\n",
        "    return [\"\".join(x) for x in output]\n",
        "\n",
        "  def _tokenize_chinese_chars(self, text):\n",
        "    \"\"\"Adds whitespace around any CJK character.\"\"\"\n",
        "    output = []\n",
        "    for char in text:\n",
        "      cp = ord(char)\n",
        "      if self._is_chinese_char(cp):\n",
        "        output.append(\" \")\n",
        "        output.append(char)\n",
        "        output.append(\" \")\n",
        "      else:\n",
        "        output.append(char)\n",
        "    return \"\".join(output)\n",
        "\n",
        "  def _is_chinese_char(self, cp):\n",
        "    \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n",
        "    # This defines a \"chinese character\" as anything in the CJK Unicode block:\n",
        "    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n",
        "    #\n",
        "    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n",
        "    # despite its name. The modern Korean Hangul alphabet is a different block,\n",
        "    # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n",
        "    # space-separated words, so they are not treated specially and handled\n",
        "    # like the all of the other languages.\n",
        "    if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
        "        (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
        "        (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
        "        (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
        "        (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
        "        (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
        "        (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
        "        (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
        "      return True\n",
        "\n",
        "    return False\n",
        "\n",
        "  def _clean_text(self, text):\n",
        "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
        "    output = []\n",
        "    for char in text:\n",
        "      cp = ord(char)\n",
        "      if cp == 0 or cp == 0xfffd or _is_control(char):\n",
        "        continue\n",
        "      if _is_whitespace(char):\n",
        "        output.append(\" \")\n",
        "      else:\n",
        "        output.append(char)\n",
        "    return \"\".join(output)\n",
        "\n",
        "\n",
        "class WordpieceTokenizer(object):\n",
        "  \"\"\"Runs WordPiece tokenziation.\"\"\"\n",
        "\n",
        "  def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n",
        "    self.vocab = vocab\n",
        "    self.unk_token = unk_token\n",
        "    self.max_input_chars_per_word = max_input_chars_per_word\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    \"\"\"Tokenizes a piece of text into its word pieces.\n",
        "\n",
        "    This uses a greedy longest-match-first algorithm to perform tokenization\n",
        "    using the given vocabulary.\n",
        "\n",
        "    For example:\n",
        "      input = \"unaffable\"\n",
        "      output = [\"un\", \"##aff\", \"##able\"]\n",
        "\n",
        "    Args:\n",
        "      text: A single token or whitespace separated tokens. This should have\n",
        "        already been passed through `BasicTokenizer.\n",
        "\n",
        "    Returns:\n",
        "      A list of wordpiece tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    text = convert_to_unicode(text)\n",
        "\n",
        "    output_tokens = []\n",
        "    for token in whitespace_tokenize(text):\n",
        "      chars = list(token)\n",
        "      if len(chars) > self.max_input_chars_per_word:\n",
        "        output_tokens.append(self.unk_token)\n",
        "        continue\n",
        "\n",
        "      is_bad = False\n",
        "      start = 0\n",
        "      sub_tokens = []\n",
        "      while start < len(chars):\n",
        "        end = len(chars)\n",
        "        cur_substr = None\n",
        "        while start < end:\n",
        "          substr = \"\".join(chars[start:end])\n",
        "          if start > 0:\n",
        "            substr = \"##\" + substr\n",
        "          if substr in self.vocab:\n",
        "            cur_substr = substr\n",
        "            break\n",
        "          end -= 1\n",
        "        if cur_substr is None:\n",
        "          is_bad = True\n",
        "          break\n",
        "        sub_tokens.append(cur_substr)\n",
        "        start = end\n",
        "\n",
        "      if is_bad:\n",
        "        output_tokens.append(self.unk_token)\n",
        "      else:\n",
        "        output_tokens.extend(sub_tokens)\n",
        "    return output_tokens\n",
        "\n",
        "\n",
        "def _is_whitespace(char):\n",
        "  \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
        "  # \\t, \\n, and \\r are technically control characters but we treat them\n",
        "  # as whitespace since they are generally considered as such.\n",
        "  if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "    return True\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat == \"Zs\":\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def _is_control(char):\n",
        "  \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
        "  # These are technically control characters but we count them as whitespace\n",
        "  # characters.\n",
        "  if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "    return False\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat in (\"Cc\", \"Cf\"):\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def _is_punctuation(char):\n",
        "  \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
        "  cp = ord(char)\n",
        "  # We treat all non-letter/number ASCII as punctuation.\n",
        "  # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
        "  # Punctuation class but we treat them as punctuation anyways, for\n",
        "  # consistency.\n",
        "  if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
        "      (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
        "    return True\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat.startswith(\"P\"):\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def preprocess_text(inputs, remove_space=True, lower=False):\n",
        "  \"\"\"Preprocesses data by removing extra space and normalize data.\n",
        "\n",
        "  This method is used together with sentence piece tokenizer and is forked from:\n",
        "  https://github.com/google-research/google-research/blob/master/albert/tokenization.py\n",
        "\n",
        "  Args:\n",
        "    inputs: The input text.\n",
        "    remove_space: Whether to remove the extra space.\n",
        "    lower: Whether to lowercase the text.\n",
        "\n",
        "  Returns:\n",
        "    The preprocessed text.\n",
        "\n",
        "  \"\"\"\n",
        "  outputs = inputs\n",
        "  if remove_space:\n",
        "    outputs = \" \".join(inputs.strip().split())\n",
        "\n",
        "  if six.PY2 and isinstance(outputs, str):\n",
        "    try:\n",
        "      outputs = six.ensure_text(outputs, \"utf-8\")\n",
        "    except UnicodeDecodeError:\n",
        "      outputs = six.ensure_text(outputs, \"latin-1\")\n",
        "\n",
        "  outputs = unicodedata.normalize(\"NFKD\", outputs)\n",
        "  outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "  if lower:\n",
        "    outputs = outputs.lower()\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def encode_pieces(sp_model, text, sample=False):\n",
        "  \"\"\"Segements text into pieces.\n",
        "\n",
        "  This method is used together with sentence piece tokenizer and is forked from:\n",
        "  https://github.com/google-research/google-research/blob/master/albert/tokenization.py\n",
        "\n",
        "\n",
        "  Args:\n",
        "    sp_model: A spm.SentencePieceProcessor object.\n",
        "    text: The input text to be segemented.\n",
        "    sample: Whether to randomly sample a segmentation output or return a\n",
        "      deterministic one.\n",
        "\n",
        "  Returns:\n",
        "    A list of token pieces.\n",
        "  \"\"\"\n",
        "  if six.PY2 and isinstance(text, six.text_type):\n",
        "    text = six.ensure_binary(text, \"utf-8\")\n",
        "\n",
        "  if not sample:\n",
        "    pieces = sp_model.EncodeAsPieces(text)\n",
        "  else:\n",
        "    pieces = sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "  new_pieces = []\n",
        "  for piece in pieces:\n",
        "    piece = printable_text(piece)\n",
        "    if len(piece) > 1 and piece[-1] == \",\" and piece[-2].isdigit():\n",
        "      cur_pieces = sp_model.EncodeAsPieces(piece[:-1].replace(\n",
        "          SPIECE_UNDERLINE, \"\"))\n",
        "      if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "        if len(cur_pieces[0]) == 1:\n",
        "          cur_pieces = cur_pieces[1:]\n",
        "        else:\n",
        "          cur_pieces[0] = cur_pieces[0][1:]\n",
        "      cur_pieces.append(piece[-1])\n",
        "      new_pieces.extend(cur_pieces)\n",
        "    else:\n",
        "      new_pieces.append(piece)\n",
        "\n",
        "  return new_pieces\n",
        "\n",
        "\n",
        "def encode_ids(sp_model, text, sample=False):\n",
        "  \"\"\"Segments text and return token ids.\n",
        "\n",
        "  This method is used together with sentence piece tokenizer and is forked from:\n",
        "  https://github.com/google-research/google-research/blob/master/albert/tokenization.py\n",
        "\n",
        "  Args:\n",
        "    sp_model: A spm.SentencePieceProcessor object.\n",
        "    text: The input text to be segemented.\n",
        "    sample: Whether to randomly sample a segmentation output or return a\n",
        "      deterministic one.\n",
        "\n",
        "  Returns:\n",
        "    A list of token ids.\n",
        "  \"\"\"\n",
        "  pieces = encode_pieces(sp_model, text, sample=sample)\n",
        "  ids = [sp_model.PieceToId(piece) for piece in pieces]\n",
        "  return ids\n",
        "\n",
        "\n",
        "class FullSentencePieceTokenizer(object):\n",
        "  \"\"\"Runs end-to-end sentence piece tokenization.\n",
        "\n",
        "  The interface of this class is intended to keep the same as above\n",
        "  `FullTokenizer` class for easier usage.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, sp_model_file):\n",
        "    \"\"\"Inits FullSentencePieceTokenizer.\n",
        "\n",
        "    Args:\n",
        "      sp_model_file: The path to the sentence piece model file.\n",
        "    \"\"\"\n",
        "    self.sp_model = spm.SentencePieceProcessor()\n",
        "    self.sp_model.Load(sp_model_file)\n",
        "    self.vocab = {\n",
        "        self.sp_model.IdToPiece(i): i\n",
        "        for i in six.moves.range(self.sp_model.GetPieceSize())\n",
        "    }\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    \"\"\"Tokenizes text into pieces.\"\"\"\n",
        "    return encode_pieces(self.sp_model, text)\n",
        "\n",
        "  def convert_tokens_to_ids(self, tokens):\n",
        "    \"\"\"Converts a list of tokens to a list of ids.\"\"\"\n",
        "    return [self.sp_model.PieceToId(printable_text(token)) for token in tokens]\n",
        "\n",
        "  def convert_ids_to_tokens(self, ids):\n",
        "    \"\"\"Converts a list of ids ot a list of tokens.\"\"\"\n",
        "    return [self.sp_model.IdToPiece(id_) for id_ in ids]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 41.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guJMLJ8bqVBY"
      },
      "source": [
        "# Create tokenizer \" Instantiate FullTokenizer\" \n",
        "# name must be \"tokenizer\"\n",
        "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
        "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
        "# please check the \"tokenization.py\" file the complete implementation\n",
        "tokenizer = FullTokenizer(vocab_file,do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9crhPylQqVBg"
      },
      "source": [
        "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
        "\n",
        "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
        "\n",
        "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
        "\n",
        "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
        "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
        "\n",
        "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
        "\n",
        "# type of all the above arrays should be numpy arrays\n",
        "\n",
        "# after execution of this cell, you have to get \n",
        "# X_train_tokens, X_train_mask, X_train_segment\n",
        "# X_test_tokens, X_test_mask, X_test_segment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIebZbZV9bJu"
      },
      "source": [
        "# Create train and test tokens (x_train_tokens, x_test_tokens) from (x_train, x_test) using Tokenizer and \n",
        "X_train\n",
        "max_seq_length = 55\n",
        "train_tokens = []\n",
        "train_mask =[]\n",
        "#X_train_segment = []\n",
        "for i in range(X_train.shape[0]):\n",
        "  tokens = tokenizer.tokenize(X_train.values[i][0])\n",
        "  if len(tokens) < max_seq_length:\n",
        "    masked_array =np.array([1]*(len(tokens)+1) + [0]*(max_seq_length-2-len(tokens))+[1])\n",
        "    #print(masked_array)\n",
        "    tokens.extend(['[PAD]'] * ((max_seq_length-2) - len(tokens)))\n",
        "    tokens.insert(0,'[CLS]')\n",
        "    tokens.insert(54,'[SEP]')\n",
        "    train_tokens.append(tokens)\n",
        "  elif len(tokens) >= max_seq_length:\n",
        "    tokens = tokens[0:(max_seq_length-2)]\n",
        "    masked_array =np.array([1]*len(tokens))\n",
        "    #print(masked_array)\n",
        "    tokens.insert(54,'[SEP]')\n",
        "    tokens.insert(0,'[CLS]')\n",
        "    train_tokens.append(tokens)\n",
        "  train_mask.append(masked_array)\n",
        "\n",
        "X_train_mask = pd.DataFrame(train_mask).values[:,:-1]\n",
        "X_train_tokens = pd.DataFrame(train_tokens).values[:,:-1]\n",
        "segment_array=np.array([0]*max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc2gXzlYpyih"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "path1 = \"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/X_train_tokens.h5\"\n",
        "path2 = \"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/X_train_mask.h5\"\n",
        "if not os.path.isfile(path1):\n",
        "  a = X_train_tokens\n",
        "  b = X_train_mask\n",
        "  pickle.dump(a, open(path1, 'wb'))\n",
        "  pickle.dump(b, open(path2, 'wb'))\n",
        "else:\n",
        "  X_train_tokens=pickle.load(open(path1, 'rb'))\n",
        "  X_train_mask=pickle.load(open(path2, 'rb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxfW8tpGrMN4",
        "outputId": "cf473626-3510-4e73-a928-09365f700427"
      },
      "source": [
        "X_train_tokens,X_train_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([['[CLS]', 'product', 'was', ..., '[PAD]', '[PAD]', '[SEP]'],\n",
              "        ['[CLS]', 'the', 'tea', ..., '[PAD]', '[PAD]', '[SEP]'],\n",
              "        ['[CLS]', 'special', 'k', ..., '.', '[PAD]', '[SEP]'],\n",
              "        ...,\n",
              "        ['[CLS]', 'when', 'local', ..., '.', '[PAD]', '[SEP]'],\n",
              "        ['[CLS]', 'this', 'was', ..., '[PAD]', '[PAD]', '[SEP]'],\n",
              "        ['[CLS]', 'shipped', 'quickly', ..., '[PAD]', '[PAD]', '[SEP]']],\n",
              "       dtype=object), array([[1., 1., 1., ..., 0., 0., 1.],\n",
              "        [1., 1., 1., ..., 0., 0., 1.],\n",
              "        [1., 1., 1., ..., 1., 0., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 0., 1.],\n",
              "        [1., 1., 1., ..., 0., 0., 1.],\n",
              "        [1., 1., 1., ..., 0., 0., 1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTFFcOLe9Dju"
      },
      "source": [
        "l = [X_train_tokens]\n",
        "for j in l:\n",
        "  for idx , i in enumerate(j):\n",
        "    j[idx] = tokenizer.convert_tokens_to_ids(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylyggrM-yBRV"
      },
      "source": [
        "# Tokenising test data \n",
        "X_test\n",
        "max_seq_length=55\n",
        "test_tokens = list()\n",
        "test_mask =[]\n",
        "#X_train_segment = []\n",
        "for i in range(X_test.shape[0]):\n",
        "  tokens = tokenizer.tokenize(X_test.values[i][0])\n",
        "  if len(tokens) < max_seq_length:\n",
        "    masked_array =np.array([1]*(len(tokens)+1) + [0]*(max_seq_length-2-len(tokens))+[1])\n",
        "    tokens.extend(['[PAD]'] * ((max_seq_length-2) - len(tokens)))\n",
        "    tokens.insert(0,'[CLS]')\n",
        "    tokens.insert(54,'[SEP]')\n",
        "    #np.array(tokens,dtype=object).reshape(1,-1)\n",
        "    test_tokens.append(tokens)\n",
        "  else:\n",
        "    tokens = tokens[0:(max_seq_length-2)]\n",
        "    masked_array =np.array([1]*len(tokens))\n",
        "    tokens.insert(0,'[CLS]')\n",
        "    tokens.insert(54,'[SEP]')\n",
        "    test_tokens.append(tokens)\n",
        "\n",
        "  ids = tokenizer.convert_tokens_to_ids(tokens=tokens)\n",
        "  #masked_array =np.array([1]*len(tokens) + [0]*(max_seq_length-len(tokens)))\n",
        "  segment_array=np.array([0]*max_seq_length)\n",
        "  test_mask.append(masked_array)\n",
        "X_test_mask   =  pd.DataFrame(test_mask).values[:,:-1]\n",
        "X_test_tokens = pd.DataFrame(test_tokens).values[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeBzZRW9saxj"
      },
      "source": [
        "path1 = \"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/X_test_tokens.h5\"\n",
        "path2 = \"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/X_test_mask.h5\"\n",
        "if not os.path.isfile(path1):\n",
        "  a = X_test_tokens\n",
        "  b = X_test_mask\n",
        "  pickle.dump(a, open(path1, 'wb'))\n",
        "  pickle.dump(b, open(path2, 'wb'))\n",
        "else:\n",
        "  X_test_tokens=pickle.load(open(path1, 'rb'))\n",
        "  X_test_mask=pickle.load(open(path2, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL2SPVj54Qio"
      },
      "source": [
        "l = [X_test_tokens]\n",
        "for j in l:\n",
        "  for idx , i in enumerate(j):\n",
        "    j[idx] = tokenizer.convert_tokens_to_ids(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv1-t4OjqVBj"
      },
      "source": [
        "#### Example\n",
        "<img src='https://i.imgur.com/5AhhmgU.png'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL9_6h_8V66v"
      },
      "source": [
        "max_seq_length = 55\n",
        "segment_array=np.array([0]*max_seq_length)\n",
        "X_train_segment = np.tile(segment_array.reshape(1,-1),(80000,1))\n",
        "X_test_segment = np.tile(segment_array.reshape(1,-1),(X_test.shape[0],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxhggBxwqVBj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF0idMRDqVBm"
      },
      "source": [
        "##save all your results to disk so that, no need to run all again.\n",
        "import pickle\n",
        "path1='/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/train_data.pkl'\n",
        "path2 = '/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/test_data.pkl'\n",
        "\n",
        "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open(path1,'wb' ))\n",
        "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open(path2,'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leu1URGzqVBo"
      },
      "source": [
        "#you can load from disk\n",
        "X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(path1, 'rb')) \n",
        "X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(path2, 'rb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfi39Qth3cAQ",
        "outputId": "4d9bad69-a46f-4564-b767-8221e70ef7fa"
      },
      "source": [
        "X_train.shape,X_train_tokens.shape,X_train_mask.shape, X_train_segment.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80000, 1), (80000, 55), (80000, 55), (80000, 55), (80000,))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEj-Eua5qVBx"
      },
      "source": [
        "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
        "We already created the BERT model in the part-2 and input data in the part-3. \n",
        "We will utlize those two and will get the embeddings for each sentence in the \n",
        "Train and test data.</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_MdIHfIyx4j"
      },
      "source": [
        "## Loading the Pretrained Model from tensorflow HUB\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
        "max_seq_length = 55\n",
        "\n",
        "#BERT takes 3 inputs\n",
        "\n",
        "#this is input words. Sequence of words represented as integers\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "#mask vector if you are padding anything\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
        "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
        "#second seq segment vector are 1's\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "#bert layer \n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "#Bert model\n",
        "#We are using only pooled output not sequence out. \n",
        "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
        "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxdIlOIBlm7j"
      },
      "source": [
        "# get the train output, BERT model will give one output so save in\n",
        "# X_train_pooled_output\n",
        "path = '/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/final_output.pkl'\n",
        "a,a_ = tf.convert_to_tensor(X_train_tokens, dtype='int32'), tf.convert_to_tensor(X_test_tokens, dtype='int32')\n",
        "b,b_ = tf.convert_to_tensor(X_train_mask, dtype='int32'), tf.convert_to_tensor(X_test_mask, dtype='int32')\n",
        "c,c_ = tf.convert_to_tensor(X_train_segment, dtype='int32'), tf.convert_to_tensor(X_test_segment, dtype='int32')\n",
        "X_train_pooled_output = bert_model.predict([a,b,c])\n",
        "X_test_pooled_output=bert_model.predict([a_,b_,c_])\n",
        "pickle.dump((X_train_pooled_output, X_test_pooled_output),open(path,'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LInMZJp5bTq8",
        "outputId": "01b625ed-653a-4a16-b3b0-31309f5b119a"
      },
      "source": [
        "X_train_pooled_output.shape,X_test_pooled_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80000, 768), (20000, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwS1QbAqVCD"
      },
      "source": [
        "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
        "\n",
        "Create a NN and train the NN. \n",
        "1.<b> You have to use AUC as metric.</b> \n",
        "2. You can use any architecture you want. \n",
        "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
        "4. Print the loss and metric at every epoch. \n",
        "5. You have to submit without overfitting and underfitting. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8PQlYRqVCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9a5216-3edc-4486-f602-04981ba15a03"
      },
      "source": [
        "##imports\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input = Input(shape=(768),name='input')\n",
        "hidden1 = Dense(16,activation='relu',name = 'Dense1')(input)\n",
        "drop1 = Dropout(0.30,name = 'Dropout1')(hidden1)\n",
        "hidden2 = Dense(32, activation='relu',name = 'Dense2')(drop1)\n",
        "drop2 = Dropout(0.30, name = 'Dropout2')(hidden2)\n",
        "hidden3 = Dense(48, activation='relu',name = 'Dense3')(drop2)\n",
        "output = Dense(2, activation='softmax',name = 'target')(hidden3)\n",
        "model = Model(inputs=input,outputs=output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 768)]             0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 16)                12304     \n",
            "                                                                 \n",
            " Dropout1 (Dropout)          (None, 16)                0         \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 32)                544       \n",
            "                                                                 \n",
            " Dropout2 (Dropout)          (None, 32)                0         \n",
            "                                                                 \n",
            " Dense3 (Dense)              (None, 48)                1584      \n",
            "                                                                 \n",
            " target (Dense)              (None, 2)                 98        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,530\n",
            "Trainable params: 14,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSnmX3WnqVCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa161f1-12ec-4acf-d206-d33da0d5223d"
      },
      "source": [
        "##create an NN and \n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "import datetime\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/checkpoint_model.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3),   \n",
        "    model_checkpoint_callback,tensorboard]\n",
        "\n",
        "\n",
        "%load_ext tensorboard \n",
        "!rm -rf ./logs/\n",
        "\n",
        "model.compile(loss= tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer = Adam(0.0001),\n",
        "              metrics=[tf.keras.metrics.AUC()])        \n",
        "\n",
        "#model.load_weights(checkpoint_filepath)\n",
        "in_ = [X_train_pooled_output]\n",
        "\n",
        "in_val =[X_test_pooled_output]\n",
        "\n",
        "out_ = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "\n",
        "out_val = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "\n",
        "#%tensorboard --logdir logs3\n",
        "history = model.fit(in_, out_,\n",
        "                    epochs=10,validation_data=(in_val,out_val),\n",
        "                    verbose=2,callbacks=my_callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 8s - loss: 0.3946 - auc_2: 0.8928 - val_loss: 0.3395 - val_auc_2: 0.9448 - 8s/epoch - 3ms/step\n",
            "Epoch 2/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.3117 - auc_2: 0.9413 - val_loss: 0.2593 - val_auc_2: 0.9589 - 7s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 8s - loss: 0.2645 - auc_2: 0.9550 - val_loss: 0.2296 - val_auc_2: 0.9665 - 8s/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.2454 - auc_2: 0.9604 - val_loss: 0.2197 - val_auc_2: 0.9713 - 7s/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.2353 - auc_2: 0.9632 - val_loss: 0.2135 - val_auc_2: 0.9727 - 7s/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.2295 - auc_2: 0.9645 - val_loss: 0.2073 - val_auc_2: 0.9703 - 7s/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.2261 - auc_2: 0.9657 - val_loss: 0.2027 - val_auc_2: 0.9741 - 7s/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.2214 - auc_2: 0.9668 - val_loss: 0.2009 - val_auc_2: 0.9743 - 7s/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.2188 - auc_2: 0.9672 - val_loss: 0.2014 - val_auc_2: 0.9748 - 7s/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 - 7s - loss: 0.2181 - auc_2: 0.9675 - val_loss: 0.1948 - val_auc_2: 0.9756 - 7s/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYs7YCfNmRp6",
        "outputId": "4ef20351-506b-4e42-8042-eacde88db619"
      },
      "source": [
        "history.history['auc_2'],history.history['loss'],history.history['val_auc_2'],history.history['val_loss']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.8927921652793884,\n",
              "  0.9413135647773743,\n",
              "  0.9550147652626038,\n",
              "  0.9603726863861084,\n",
              "  0.9631730914115906,\n",
              "  0.9644957184791565,\n",
              "  0.965663492679596,\n",
              "  0.9668259024620056,\n",
              "  0.9672496914863586,\n",
              "  0.9675120115280151],\n",
              " [0.39460140466690063,\n",
              "  0.3117092549800873,\n",
              "  0.26453354954719543,\n",
              "  0.2454274445772171,\n",
              "  0.23525963723659515,\n",
              "  0.2294992208480835,\n",
              "  0.2261458933353424,\n",
              "  0.22139513492584229,\n",
              "  0.2187579870223999,\n",
              "  0.21811242401599884],\n",
              " [0.9448151588439941,\n",
              "  0.9588866233825684,\n",
              "  0.9664859175682068,\n",
              "  0.9713059067726135,\n",
              "  0.9727246165275574,\n",
              "  0.9703205823898315,\n",
              "  0.9740658402442932,\n",
              "  0.9743203520774841,\n",
              "  0.9748466610908508,\n",
              "  0.9756230115890503],\n",
              " [0.3394814729690552,\n",
              "  0.25926193594932556,\n",
              "  0.22957459092140198,\n",
              "  0.2197338193655014,\n",
              "  0.2134840041399002,\n",
              "  0.20726104080677032,\n",
              "  0.20271220803260803,\n",
              "  0.20085905492305756,\n",
              "  0.20137403905391693,\n",
              "  0.1947917342185974])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IdUCBILAm4er",
        "outputId": "e6e957b4-e231-4928-9898-5cdbaa4c4039"
      },
      "source": [
        "history.history['auc_2'],history.history['loss'],history.history['val_auc_2'],history.history['val_loss']\n",
        "plt.plot(history.history['auc_2'],label='train_accuracy')\n",
        "plt.plot(history.history['val_auc_2'],label = 'validation_accuracy')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.title('Accuracy_plot')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "KfEyspHinRSF",
        "outputId": "a4226100-f01a-4d22-817b-daaa9c4f296c"
      },
      "source": [
        "#with lr=0.0033\n",
        "history.history['auc_2'],history.history['loss'],history.history['val_auc_2'],history.history['val_loss']\n",
        "plt.plot(history.history['loss'],label='train_loss')\n",
        "plt.plot(history.history['val_loss'],label = 'validation_loss')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.title('loss_plot')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcILeYZI9pxm"
      },
      "source": [
        "<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n",
        "\n",
        "1. Download data from <a href=\"https://drive.google.com/file/d/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo/view?usp=sharing\">here</a>\n",
        "2. Read the csv file\n",
        "3. Remove all the html tags\n",
        "4. Now do tokenization [Part 3 as mentioned above]\n",
        "    * Create tokens,mask array and segment array\n",
        "5. Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
        "   * Print the shape of output(X_test.shape).You should get (352,768)\n",
        "6. Predit the output of X_test with the Neural network model which we trained earlier.\n",
        "7. Print the occurences of class labels in the predicted output\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC8stpJ5ROge"
      },
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5T5iyKhSNmT"
      },
      "source": [
        "test\n",
        "import re\n",
        "test.Text=test.Text.apply(lambda x :re.sub(r'<.*?>', '',x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiBeOnna9yDH"
      },
      "source": [
        "def token_to_id(data):\n",
        "  for idx , i in enumerate(data):\n",
        "    data[idx] = tokenizer.convert_tokens_to_ids(i)\n",
        "\n",
        "\n",
        "def token_mask_segment(data,max_len):\n",
        "  max_seq_length = max_len\n",
        "  train_tokens = []\n",
        "  train_mask = []\n",
        "  for i in range(data.shape[0]):\n",
        "    tokens = tokenizer.tokenize(data.values[i][0])\n",
        "    if len(tokens) < max_seq_length:\n",
        "      masked_array =np.array([1]*(len(tokens)+1) + [0]*(max_seq_length-2-len(tokens))+[1])\n",
        "      tokens.extend(['[PAD]'] * ((max_seq_length-2) - len(tokens)))\n",
        "      tokens.insert(0,'[CLS]')\n",
        "      tokens.insert(54,'[SEP]')\n",
        "      train_tokens.append(tokens)\n",
        "    elif len(tokens) >= max_seq_length:\n",
        "      tokens = tokens[0:(max_seq_length-2)]\n",
        "      masked_array =np.array([1]*len(tokens))\n",
        "      tokens.insert(54,'[SEP]')\n",
        "      tokens.insert(0,'[CLS]')\n",
        "      train_tokens.append(tokens)\n",
        "    train_mask.append(masked_array)\n",
        "  X_train_mask = pd.DataFrame(train_mask).values[:,:-1]\n",
        "  X_train_tokens = pd.DataFrame(train_tokens).values[:,:-1]\n",
        "  token_to_id(X_train_tokens)\n",
        "  segment_array=np.array([0]*max_seq_length)\n",
        "  X_segment_array = np.tile(segment_array.reshape(1,-1),(data.shape[0],1))\n",
        "  return X_train_mask,X_train_tokens,X_segment_array\n",
        "\n",
        "#2\n",
        "path = '/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/output.pkl'\n",
        "def bert_output_features(model_pooled,mask,token,segment,path):\n",
        "  if not os.path.isfile(path):\n",
        "    a = tf.convert_to_tensor(token, dtype='int32')\n",
        "    b = tf.convert_to_tensor(mask, dtype='int32')\n",
        "    c = tf.convert_to_tensor(segment, dtype='int32')\n",
        "    X_pooled_output = model_pooled.predict([a,b,c])\n",
        "    pickle.dump((X_pooled_output),open(path,'wb'))\n",
        "  else:\n",
        "    X_pooled_output = pickle.load(open(path, 'rb'))\n",
        "  return X_pooled_output\n",
        "\n",
        "\n",
        "def pipeline(data,model_pooled,model,path,max_len):\n",
        "  mask,tokens,segment_array = token_mask_segment(data,max_len)\n",
        "  print(mask.shape,tokens.shape,segment_array.shape)\n",
        "  x = bert_output_features(model_pooled,mask,tokens,segment_array,path)\n",
        "  #print(x.shape,x)\n",
        "  predict = model.predict(x)\n",
        "  return predict\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_37NyaHpMO4",
        "outputId": "e9a7f1ca-4627-4524-8d9e-119ed5fa7d7d"
      },
      "source": [
        "#Data Pipeline\n",
        "path1 = '/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/NLP with transfer learning/output_pooled2.pkl'\n",
        "predict = pipeline(data = test,model_pooled=bert_model,model=model,path= path1,max_len=55)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(352, 55) (352, 55) (352, 55)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfyj2wf8ZVo4",
        "outputId": "76973914-9015-4192-cde8-d91fd78ef526"
      },
      "source": [
        "# Respective probabilities of both the classes.\n",
        "predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.71200299e-01, 2.28799731e-01],\n",
              "       [3.43992870e-04, 9.99655962e-01],\n",
              "       [4.04406875e-01, 5.95593095e-01],\n",
              "       [3.21229808e-02, 9.67877090e-01],\n",
              "       [3.34966253e-03, 9.96650398e-01],\n",
              "       [4.43309516e-01, 5.56690514e-01],\n",
              "       [6.29757345e-01, 3.70242625e-01],\n",
              "       [6.22447697e-05, 9.99937773e-01],\n",
              "       [3.92483016e-05, 9.99960780e-01],\n",
              "       [2.47629232e-05, 9.99975204e-01],\n",
              "       [3.61913532e-01, 6.38086498e-01],\n", dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "7jIHHPjXnD8t",
        "outputId": "d9858e62-8326-467c-b894-8a3146351d86"
      },
      "source": [
        "# Count of both the classess \n",
        "label_predict = []\n",
        "for i in predict:\n",
        "  if i[1]>i[0]:\n",
        "    label_predict.append(1)\n",
        "  else:\n",
        "    label_predict.append(0)  \n",
        "\n",
        "\n",
        "label_predict = np.array(label_predict)\n",
        "ones = np.sum(label_predict==1)\n",
        "zeros = np.sum(label_predict==0)\n",
        "print(\"--------- 1:\",ones,'--------- \\n0:',zeros)\n",
        "\n",
        "import seaborn as sns\n",
        "sns.countplot(label_predict)\n",
        "plt.title('Count_plot')\n",
        "plt.xlabel('labels')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: 308 \n",
            "0: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsEpxFjfr9Rg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nao6zWdwo1-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff302ad-0815-4dbd-baf4-d05b39189a8e"
      },
      "source": [
        "label_predict = np.array(label_predict)\n",
        "label_predict\n",
        "\n",
        "# 1: 308 (Positive )\n",
        "# 0: 44  (Negetive)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3SOZ-UFS3c1"
      },
      "source": [
        "#Steps followed were as follows (Summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shvUTG6Lmgq4"
      },
      "source": [
        "#Steps followed were as follows\n",
        "1) here as we have been given amazon food reviews for text classification,first step was to preprocess the data by removing \n",
        "special characters and https characters.followed by train test split .after that each sentence was tokenised and positional encoded as per \n",
        "embedded dictionary with first word as '[CLS]':101 and last one as '[SEP]':102.also we added '[PAD]' tokens to get each sentence of fixed length \n",
        "say (512) as senteses with different length dont seem to work with RNN.\n",
        "\n",
        "2)along with positional encoded vectors masked and segment arrays are also created by masking positional encoded vectors\n",
        "replacing 0 with all the tokens '[PAD]' and 1 for rest of the tokens.and zero vectors as segmengt array of required length.\n",
        "\n",
        "#['[CLS]', 'product', 'was', ..., '[PAD]', '[PAD]', '[SEP]'] ---> length = 512\n",
        "#                         | |\n",
        "#[101,-----------------------------------------------,102] positional encoded vector\n",
        "#[1,1,1,0,0,0----------0,0,1] --------> length = 512       masked vector\n",
        "#[0,0,0,0,0,0,0,0,0,0,0,0,0] ---------->length = 512        segment array\n",
        "\n",
        "3) we feed these positional encoded vectors to uncased bert model for generating vectors corresponding to each token with output dimension of 768\n",
        "i.e here bert model is used for feature extraction with output tensors of shape (None,512,768). under the hood this feature extraction is done by encoder architecture\n",
        "having layers for self attention followed by feedforward neural network along with layer normalization and addition. \n",
        "\n",
        "4) with these extracted features we trained a simple neural net for binary classification (positive or negetive) review\n",
        "follwed by building a data pipeline to accept new test sentences for predicting the classes and used the previously trained model \n",
        "to predict the class output of each text sentence.\n",
        "\n",
        "#['[CLS]', 'product', 'was', ..., '[PAD]', '[PAD]', '[SEP]']\n",
        "#                         | |\n",
        "#[101,-----------------------------------------------,102]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
